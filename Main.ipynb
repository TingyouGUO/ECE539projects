{"cells":[{"cell_type":"markdown","metadata":{"id":"GIddArdZ6z4W"},"source":["# Triple Negative Breast Cancer(TNBC) Cell Semantic Segmentation\n","\n","This notebook applies [U-Net](https://arxiv.org/abs/1505.04597) Convolutional Neural Network for semantic segmentation of TNBC cell images.\n","\n","The dataset for the task is downloaded from [here](https://zenodo.org/record/1175282#.Xl_4nZMzZQJ) \n","\n","**Flow of the notebook:**\n","- Apply U-Net to standard dataset \n","- Plot network's perfomance \n","- Show sample test segmentation results \n","- Apply U-Net to dataset \"overlayed\" with canny edges\n","- Plot network's perfomance \n","- Show sample test segmentation results \n","- Compare newtork's performance on both datasets\n","\n","Let's get started!"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWxyQg6qEBug","executionInfo":{"status":"ok","timestamp":1659996156956,"user_tz":-60,"elapsed":1305,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}},"outputId":"88e1349a-fc2b-495c-a25f-b7398005ebec"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","\n","path = \"/content/drive/MyDrive/U-Net-Breast-Cancer-Image-Segmentation-master\"\n","os.chdir(path)"],"metadata":{"id":"DEzNizs8EEKN","executionInfo":{"status":"ok","timestamp":1659996160433,"user_tz":-60,"elapsed":2,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"JYYMGl1Qr-GJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4W0lmtI6z4Z"},"source":["# Triple Negative Breast Cancer\n","\n","*Triple-negative breast cancer (TNBC) accounts for about 10-15%  of all breast cancers. These cancers tend to be more common in women younger than age 40, who are African-American.*\n","\n","*Triple-negative breast cancer differs from other types of invasive breast cancer in that they grow and spread faster, have limited treatment options, and a worse prognosis (outcome)*.  - **American Cancer Society**\n","\n","Thus early stage cancer detection is required to provide proper treatment to the patient and reduce the risk of death due to cancer as detection of these cancer cells at later stages lead to more suffering and increases chances of death. Semantic segmentation of cancer cell images can be used to improvise the analysis and diagonsis of Breast Cancer! Below is such an attempt."]},{"cell_type":"markdown","metadata":{"id":"U59LqcCi6z4a"},"source":["# U-Net\n","\n","U-Net is a State of the Art CNN architecture for Bio-medical image segmentation. *The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization.* It's a Fully Convolutional Network(FCN) therefore it can **work with arbitrary size images!**\n","\n","<img src=\"img/U-Net_arch.png\">"]},{"cell_type":"code","source":["! pip install tensorflow==1.15.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80x8BwKeOP3b","executionInfo":{"status":"ok","timestamp":1659996249544,"user_tz":-60,"elapsed":2989,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}},"outputId":"3c7bc640-6b3b-4802-ccbe-ad1b439866b5"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.2.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.47.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.37.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.19.4)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.14.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.21.6)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.1.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n"]}]},{"cell_type":"code","source":["import tensorflow\n","print(tensorflow.__version__)"],"metadata":{"id":"tggpAgR7OXX1","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1659996020969,"user_tz":-60,"elapsed":8,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}},"outputId":"5cf067aa-4c0e-472b-e09e-6429afe2ed54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-15-53968207222e>\", line 1, in <module>\n","    import tensorflow\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 99, in <module>\n","    from tensorflow_core import *\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/__init__.py\", line 28, in <module>\n","    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n","ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow.python' (unknown location)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/__init__.py\", line 28, in <module>\n","    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1246, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1115, in __iter__\n","  File \"<frozen importlib._bootstrap_external>\", line 1103, in _recalculate\n","  File \"<frozen importlib._bootstrap_external>\", line 1099, in _get_parent_path\n","KeyError: 'tensorflow'\n"]},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!pip install tf-nightly-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ji7ZCt4yRBGj","outputId":"2df030f1-ac34-458a-f9a0-f6186129e74e","executionInfo":{"status":"ok","timestamp":1659996179339,"user_tz":-60,"elapsed":3128,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tf-nightly-gpu in /usr/local/lib/python3.7/dist-packages (2.11.0.dev20220808)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.47.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (57.4.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (20.9)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (4.1.1)\n","Requirement already satisfied: tb-nightly~=2.10.0.a in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (2.10.0a20220808)\n","Requirement already satisfied: tf-estimator-nightly~=2.11.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (2.11.0.dev2022080808)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.1.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.15.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (3.19.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.1.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (0.2.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (0.26.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (1.2.0)\n","Requirement already satisfied: keras-nightly~=2.11.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (2.11.0.dev2022080807)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (14.0.6)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly-gpu) (3.1.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tf-nightly-gpu) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly-gpu) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (2.23.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly-gpu) (1.8.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly-gpu) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly-gpu) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly-gpu) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly-gpu) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly-gpu) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly-gpu) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly-gpu) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly-gpu) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly-gpu) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly-gpu) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly-gpu) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly-gpu) (3.2.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-nightly-gpu) (3.0.9)\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AT-1onYCtWcy","outputId":"621c692a-fdbe-4cdb-a589-1408b9bff167","executionInfo":{"status":"error","timestamp":1659996184045,"user_tz":-60,"elapsed":395,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-19-bb582619fdbe>\", line 4, in <module>\n","    import tensorflow as tf\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 99, in <module>\n","    from tensorflow_core import *\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/__init__.py\", line 28, in <module>\n","    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n","ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow.python' (unknown location)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/__init__.py\", line 28, in <module>\n","    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1246, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1115, in __iter__\n","  File \"<frozen importlib._bootstrap_external>\", line 1103, in _recalculate\n","  File \"<frozen importlib._bootstrap_external>\", line 1099, in _get_parent_path\n","KeyError: 'tensorflow'\n"]},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# To ensure GPU is enabled on Colab\n","\n","%matplotlib inline\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"markdown","metadata":{"id":"I6HzS4To6z4_"},"source":["## 1- Import required modules"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"euvHX8pdto12","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1659996191071,"user_tz":-60,"elapsed":543,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}},"outputId":"871c6db1-de4e-4d31-9fb6-f83d334f9780"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-942b1f6a67f9>\", line 1, in <module>\n","    from model import *\n","  File \"/content/drive/.shortcut-targets-by-id/1312aga1iOmQ2u72zeDzzFUpEQFd4oIKo/U-Net-Breast-Cancer-Image-Segmentation-master/model.py\", line 8, in <module>\n","    from tensorflow.keras.models import *\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 959, in _find_and_load_unlocked\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/__init__.py\", line 28, in <module>\n","    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1246, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1115, in __iter__\n","  File \"<frozen importlib._bootstrap_external>\", line 1103, in _recalculate\n","  File \"<frozen importlib._bootstrap_external>\", line 1099, in _get_parent_path\n","KeyError: 'tensorflow'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/__init__.py\", line 28, in <module>\n","    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1246, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1115, in __iter__\n","  File \"<frozen importlib._bootstrap_external>\", line 1103, in _recalculate\n","  File \"<frozen importlib._bootstrap_external>\", line 1099, in _get_parent_path\n","KeyError: 'tensorflow'\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}],"source":["from model import *\n","from augmentation import *\n","from metrics import *\n","from plots import *\n","from utils import *"]},{"cell_type":"markdown","metadata":{"id":"PrYe6qy46z5Y"},"source":["### 1.1- How to arrange Directories for using ImageDataGenerator.flow_from_directory()?\n","\n","- train\n","    * images\n","        * img\n","    * label\n","        * img\n","- test\n","    * images\n","        * img\n","    * label\n","        * img\n","        \n","**train, test, images, label,img** are all directories, where *img* is the directory containing images/segmentation masks .png images"]},{"cell_type":"code","source":["#### 'model.py' module contains the U-Net architecture definition which is the model we use for Semantic Segmentation \n","\n","import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","from tensorflow import keras \n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras import backend as keras\n","\n","\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    \"\"\"Initialises Keras Model instance. The following architecture is similar to the original U-Net \n","        architecture, except I've used \"same\" padding instead \"valid\" which the authors have used. Using \"same\"\n","        padding throughout makes the output segmentation mask of same (height, width) as that of the input.\n","        For detailed U-Net architecture check: https://arxiv.org/abs/1505.04597\n","\n","    Args:\n","        pretrained_weights (.hdf5 file): Weights to pre-train our model\n","        input_size (tuple): Input shape of images to the model\n","\n","    Returns:\n","        model (Model): Keras Model instance is the model we use \n","    \"\"\"\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(inputs = inputs, outputs = conv10)\n","\n","    # If pre-trained weights are provided load it \n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model\n","\n","\n"],"metadata":{"id":"M2OIJhTiVq9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bhd1nyCLuR2e","cellView":"code"},"outputs":[],"source":["#@title Default title text\n","# Loads and initalises the U-Net network\n","\n","m=unet()\n","m.summary()"]},{"cell_type":"code","source":["from tensorflow.keras.utils import plot_model\n","plot_model(m, to_file=os.path.join('/content/drive/MyDrive/U-Net-Breast-Cancer-Image-Segmentation-master','model_plot.png'), show_shapes=True, show_layer_names=True)"],"metadata":{"id":"hphZk8A8GD2F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4tJ-13Ji6z5p"},"source":["## 2- Model training on Standard Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIC5MzZqx7L5"},"outputs":[],"source":["opt = Adam(lr=1E-6, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","m.compile(loss=dice_coef_loss, optimizer=opt, metrics=['accuracy', iou, F1, recall, precision]) # Keeping track of these metrics"]},{"cell_type":"code","source":["Adam"],"metadata":{"id":"GeuKNSpnhIjB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6NB1hlp06z5v"},"source":["2.1- Why Data Augmentation?\n","\n","Our training set has **only 33 images** which is nothing when compared to modern day datasets like [ImageNet](http://www.image-net.org/) which has over 1M annotated examples. *But this is generally the case in Bio-medical tasks.* Thus I've used Data Augmentation extensively to increase the dataset."]},{"cell_type":"markdown","metadata":{"id":"hK75OnnH6z5w"},"source":["### 2.2- Why I haven't used ImageNet for Transfer Learning?\n","\n","You might be wondering why haven't I done \"transfer learning\" from ImageNet or any similar datasets? Afterall such pre-training is a standard for Deep Learning. \n","\n","ImageNet is a \"natural image\" dataset and I'm here tacking a very specific problem which has images very different from natural images. Thus such pre-training would provide *little* benefit to the performance. For detailed insight into this check [this](https://arxiv.org/abs/1902.07208) wonderful paper which digs deep into Transfer learning for Medical tasks."]},{"cell_type":"code","source":["!apt-cache policy libcudnn8\n","\n","# Install latest version\n","!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6\n","\n","# Export env variables\n","!export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}\n","!export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64:$LD_LIBRARY_PATH\n","!export LD_LIBRARY_PATH=/usr/local/cuda-11.4/include:$LD_LIBRARY_PATH\n","!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\n","\n","# Install tensorflow\n","!pip install tflite-model-maker==0.4.0\n","!pip uninstall -y tensorflow && pip install -q tensorflow==2.9.1\n","!pip install pycocotools==2.0.4\n","!pip install opencv-python-headless==4.6.0.66"],"metadata":{"id":"FUPeS2fDXhEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"id":"n4TxOY8euVPR","outputId":"fe18fdac-0fd0-4879-cf4f-b7eae1481536","scrolled":true,"executionInfo":{"status":"error","timestamp":1659995908683,"user_tz":-60,"elapsed":8,"user":{"displayName":"YIWEN XU","userId":"14351302883367640401"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 35 images belonging to 1 classes.\n","Found 35 images belonging to 1 classes.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-304eeefc7de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                          \u001b[0;31m# Weights will be saved in file named 'unet_weights.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Peforms real-time Data Augmentation on the Training dataset. See augmentation.py for more details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mconvert_to_generator_like\u001b[0;34m(data, batch_size, steps_per_epoch, epochs, shuffle)\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'zip' object has no attribute 'shape'"]}],"source":["checkpoint = ModelCheckpoint('unet_weights.hdf5', monitor='loss', \n","                             verbose=1, save_best_only=True, mode='min') # Checkpoint to store \"only\" the best weights during training\n","                                                                         # Weights will be saved in file named 'unet_weights.hdf5'\n","train_generator=train_data_aug() # Peforms real-time Data Augmentation on the Training dataset. See augmentation.py for more details\n","results = m.fit_generator(train_generator, epochs=50, steps_per_epoch = 16, callbacks=[checkpoint])"]},{"cell_type":"markdown","metadata":{"id":"yWk9dHa16z55"},"source":["## 3- Plotting model's training history"]},{"cell_type":"markdown","metadata":{"id":"ttxkbwjU6z55"},"source":["### 3.1- Why is the Learning Curve such?\n","\n","I've trained the model before many times and in previous trainings the \"Learning Curve\" was exactly as a good learning curve should be ie. noisyier but \"trending\" downward for Loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRcFn8D7uf3q"},"outputs":[],"source":["from plots import *\n","\n","training_history_plot(results) # Plots \"training curve\" for the network/model for metrics listed above. See plots.py for more details"]},{"cell_type":"markdown","metadata":{"id":"eyvB3IrR6z6K"},"source":["## 4- Model's Performance on various Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKKBtDiYujkG"},"outputs":[],"source":["titles = ['Dice Loss','Accuracy','IOU','F1','Recall','Precision']\n","test_generator=test_data_aug() # Peforms real-time Data Augmentation(here only re-scaling and converting to grayscale) on the Test/Validation dataset. See augmentation.py for more details\n","performance=m.evaluate_generator(test_generator, verbose=1,steps=5)\n","\n","for i in range(6):\n","  print(\"%s = %f\" %(titles[i], performance[i]))"]},{"cell_type":"markdown","metadata":{"id":"kPTrBLYl6z6n"},"source":["### 4.1- Structure of test2 directory\n","\n","- test2\n","    * 0\n","        * 0\n","            * 0.png\n","    * 1\n","        * 1\n","            * 1.png\n","            \n","Such weird file structure is because there should be **\"two\" nested directories** in the container directory(test2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PI-t_hlunXI"},"outputs":[],"source":["results=np.zeros(shape=(5,256,256,1))\n","for i in range(5): # As we have 17 test images \n","\n","  results[i,:,:,:]=predict(i, m) # Predicts the segmentation labels on images in test2 directory. See utils.py for more details augmentation"]},{"cell_type":"markdown","metadata":{"id":"N5DWY0wv6z6s"},"source":["## 5- Sample Results\n","\n","Starting from the left:\n","    - First image is original test image \"converted\" to grayscale\n","    - Second is the predicted segmentation labels for above image\n","    - Third one is a Binary mask ie. pixel values of only 0's and 1's, obtained by thresholding on Predicted segmentation, below is for threshold value 0.2, implies all pixel values greater than 0.2 in Predicted segmentation get 1 and others get 0\n","    - Rightmost is the Ground Truth segmentation label for this test image\n","    \n","Below we see that segmentation results are very good considering the fact that we had only 33 images our training dataset which is very limited! "]},{"cell_type":"code","source":["results.shape\n"],"metadata":{"id":"S2lQXklK2GT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvwUIdOVuwn8"},"outputs":[],"source":["model_prediction_plot(results, t=0.2) # See plots.py for more details"]},{"cell_type":"markdown","metadata":{"id":"NcQtLNdc6z7K"},"source":["## 6- Model training on Canny Dataset"]},{"cell_type":"markdown","metadata":{"id":"5qp8ciWp6z7O"},"source":["## 7- Plotting model's training history on Canny dataset"]},{"cell_type":"markdown","metadata":{"id":"IOHI6aSJ6z7P"},"source":["### 7.1- Why is the Learning Curve such?\n","\n","I've trained the model before many times and in previous trainings the \"Learning Curve\" was exactly as a good learning curve should be ie. noisier but \"trending\" downwards for the Loss function."]},{"cell_type":"markdown","metadata":{"id":"C3UoygrJ6z7V"},"source":["## 8- Model's Performance on various Metrics trained on Canny dataset"]},{"cell_type":"markdown","metadata":{"id":"9dtWTHnDZYK-"},"source":["## 9- Activation Map on Canny dataset\n","\n","Below is the visualisation of Activation Maps of the model trained on Canny dataset. These visuals are the *activations or the output* of given layer and channel of U-Net CNN. These visualisations tell us **What the model has learnt** or more specifically what the convolutional filters have learnt! It also gives a sense of the **other Biological/Medical features** in the image.\n","\n","Starting from the left:\n","    - First image is original test image\n","    - Second is the Activation Map for provided layer and channel\n","    - Third one is the Transparent \"overlay\" of the Activation Map over the test image\n","For more information see plots.py\n","\n","**Note:** As I'm using **'jet' cmap** so red corresponds to high activation values and blue to low ones, and green/yellow in the middle in the Activation Map."]},{"cell_type":"markdown","metadata":{"id":"Qw9Q4FQIZYK_"},"source":["The filter corresponding to the last layer and it's only filter has learnt to **segment Cancer cells**, marked in red in the second image! When overlayed on the original image clearly distinguishes Cancer and non-Cancer cells."]},{"cell_type":"markdown","metadata":{"id":"znYWG4tKZYK_"},"source":["As clearly seen above the corresponding filter has learnt to identify **empty regions** see red region in centre image, remember \"Red\" corresponds to high activation in Activation Map! Also note that Cancer cells have low activations here, marked in blue so in a way *this filter is ignoring those cells.*"]},{"cell_type":"markdown","metadata":{"id":"ERcgDKd6ZYLB"},"source":["Above is the visual for a middle Conv layer, thus it's neither seeing the entire image as it is nor it's segmentation mask! The \"Light Blue\" marks in the Activation Map shows that this is *tending to learn to segment Cancer cells.*"]},{"cell_type":"markdown","metadata":{"id":"fFKA2latBuPo"},"source":["## 12- References\n","\n","1. [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)\n","2. [Triple Negative Breast Cancer- American Cancer Society](https://www.cancer.org/cancer/breast-cancer/understanding-a-breast-cancer-diagnosis/types-of-breast-cancer/triple-negative.html)\n","3. [Deep Learning for Cancer Cell Detection and Segmentation: A Survey](https://www.researchgate.net/publication/334080872_Deep_Learning_for_Cancer_Cell_Detection_and_Segmentation_A_Survey)\n","4. [Transfusion: Understanding Transfer Learning for Medical Imaging](https://arxiv.org/abs/1902.07208)\n","5. [Dataset](https://zenodo.org/record/1175282#.Xl_4nZMzZQJ)\n","\n","**Note:** Not an exhaustive list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZF9ekPe66z79"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Main.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}